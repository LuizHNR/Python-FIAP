{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "996723c3-c160-4b54-91d2-092101b3ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f75ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d255f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = open(\"./train.csv\", \"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4984fd09-7e31-4454-b66c-5ddedccbe53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_arquivo( nome_arquivo):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    linha = arquivo.readline()\n",
    "    linha = arquivo.readline()\n",
    "    contador_linha = 0\n",
    "    \n",
    "    while linha != \"\":\n",
    "        #if contador_linha % 500 == 0:\n",
    "            #print(contador_linha)\n",
    "        #contador_linha += 1\n",
    "        colunas = linha.split(\",\")\n",
    "        if len(colunas) ==5:\n",
    "            texto = colunas[3].lower()\n",
    "            try:\n",
    "                label = int(colunas[4].replace(\"\\n\", \"\"))\n",
    "                x.append(texto)\n",
    "                y.append(label)\n",
    "            except:\n",
    "                pass\n",
    "        linha = arquivo.readline()\n",
    "        arquivo.close()\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2957080c-a16b-4488-9c90-7595cec84a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = ler_arquivo(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0be59d7e-d5da-4148-b77f-81cdf71a5022",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mler_arquivo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m, in \u001b[0;36mler_arquivo\u001b[1;34m(nome_arquivo)\u001b[0m\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m linha \u001b[38;5;241m=\u001b[39m \u001b[43marquivo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m linha \u001b[38;5;241m=\u001b[39m arquivo\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m      7\u001b[0m contador_linha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "x_test, y_test = ler_arquivo(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c0c2d6b-a3f0-4dc6-afa9-5cf38a06a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dicionario = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da9c6f93-86c6-4a68-8fdb-0bdb27f35b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "##def tokenizar( texto ):\n",
    "   ##return texto.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de2b6632-2d2e-4f8b-a0b6-a5a6b05faf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98b0bfc5-5e80-4bdb-b191-df2ad640648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for texto in x:\n",
    "    #x2.append(tokenizar( texto ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "164ba369-8838-41d3-829e-d26942c3df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tokens in x2:\n",
    "    #for token in tokens:\n",
    "       # if token in dicionario:\n",
    "         #   dicionario[token] += 1\n",
    "      #  else:\n",
    "         #   dicionario[token] =1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9c40c86-a91d-4c70-a6f2-cbb0518d71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavas = list(dicionario.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dbd55de-1f8c-42fa-9c0e-585a6cd9be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8ba8510-cb37-4a29-845c-53d7570e5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb1a685-578e-4944-bce8-892943f0cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4da7de1-f000-4c96-8d41-2dd18e329641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae110340-2363-457b-9221-9dafda096beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "decf3fb0-91e9-44e9-9e83-5161e165ef5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbow_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1246\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1244\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1251\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1254\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "model.fit(bow_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e543a26f-267b-4bf2-9dd3-fcc2009e521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte_vectorizer = CountVectorizer(vocabulary = vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22407964-d709-4216-aec8-c9c072277be4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teste_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bow_test \u001b[38;5;241m=\u001b[39m \u001b[43mteste_vectorizer\u001b[49m\u001b[38;5;241m.\u001b[39mfit_transform(x_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'teste_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "bow_test = teste_vectorizer.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd7e8948-aa8f-43a5-8b09-9cf37af47182",
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_vetorizador = CountVectorizer(vocabulary=vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02bfcc5a-6872-4744-beff-c283b01bb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_a_prever = novo_vetorizador.fit_transform([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e726fe7-6a5b-4e1d-a41c-7f54be8f0f12",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexto_a_prever\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:333\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "model.predict(texto_a_prever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35abdabb-fa12-46c6-82f0-d5faee17b361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
